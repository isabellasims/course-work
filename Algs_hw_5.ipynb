{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Algs hw 5",
      "provenance": [],
      "authorship_tag": "ABX9TyMINySFlI00xJNJ2/pg1egi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isabellasims/course-work/blob/master/Algs_hw_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiXO3SYa3kiz"
      },
      "source": [
        "**Question 1**\n",
        "\n",
        "*Dr. X, Systems Analyst for the Speedy-Look-Up Consulting Firm\n",
        "has the following advice:\n",
        "20% of the names in your alphabetically ordered, sequentially\n",
        "allocated, core-resident table of 10,000 names account for 80% of\n",
        "the table look-ups. Instead of carrying out a binary search over a\n",
        "single table with 10,000 entries, you should have a high-frequency\n",
        "table, where 2000 most frequently looked-up names are arranged\n",
        "alphabetically, and a low-frequently table, where the remaining\n",
        "8000 names are arranged alphabetically. When you want to look up\n",
        "a name, you search first in the small high-frequency table. 80% of\n",
        "the searches will stop right there. In only 20% of the cases will you also have to search the larger low-frequency table.\n",
        "HAPPY ENDING: Dr. X gets a salary raise for having increased\n",
        "significantly the throughput of Speedy-Look-Upâ€™s computer center.\n",
        "SAD ENDING: Dr. X gets fired for professional incompetence.\n",
        "You are the President of the Speedy-Look-Up, Chairman of the\n",
        "Board, and the main stockholder. Choose between the HAPPY and\n",
        "SAD ending.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efW_MdL5XESs"
      },
      "source": [
        "I would choose the happy ending because Dr. X is onto a good idea here. That said, it can and should be improved. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1SV7lNtW_vN"
      },
      "source": [
        "**Question 2**\n",
        "\n",
        "*Explain in detail how you made that decision, be specific and use data to justify your choice. Can you think of a better way of searching the table? Please explain in detail.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imj6yiZW-tNJ"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "**Better Ideas:**\n",
        "\n",
        "**Option 1**\n",
        "\n",
        "\n",
        "Dr. X is right that we should split the table up. However, it would be more efficient to split table up into three tables instead of 2. \n",
        "\n",
        "- The first table would stay the same as proposed (the top 20% look-ups)\n",
        "-  The second table would be the remainder of names that are looked up. \n",
        "- The third table would be names that are not looked-up.\n",
        "\n",
        "\n",
        "If a name in the third table is looked up, it should be added to the second table and removed from the first. Likewise, if a name from the second table is looked up more than a name in the first table, it should be removed from the second table and added to the first. Since everytime we move a name it will need to be resorted alphabetically, we ideally would do these steps when the system is least active. If the frequency of name look-ups changes often, we would want to do this more frequently. We should also weigh the time it takes to resort the table vs the time we save by doing so. We only want to resort the table if it saves us time. \n",
        "\n",
        "\n",
        "Aditionally, we should be doing the table look-ups as a binary search. I'm not sure if this was implied by Dr. X, but if it was not I would choose sad ending instead, as there is really no reason to alphabetically sort the names in the tables if we aren't performing a binary search on them.  \n",
        "\n",
        "\n",
        "**Option 2**\n",
        "\n",
        "A different option would be to sort the names by look-up frequency and sequentially search the first two tables. The order in which we search the tables would remain the same. We only search the second table if we didn't find our name in the first and only search the third table if we didn't find our name in the second. \n",
        "\n",
        "\n",
        "In this situation, we would want to structure the third table differetly than the first two. Since the third table is comprised of names that are not looked up, we don't sort this table by look-up frequency. Instead, we sort this table alphabetically and perform binary search on it, just as we did in the previous example. \n",
        "\n",
        "\n",
        "."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxBSWZNdKp4j"
      },
      "source": [
        "**Data example**\n",
        "\n",
        "The choice between option 1 and option 2 is dependent on the data. Consider the following two datasets represented as frequency dictionaries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUgUpwnKAf1X"
      },
      "source": [
        "# not part of the alg, just creating data-sets as examples\n",
        "import random\n",
        "table1 = []\n",
        "table2 = []\n",
        "def list_to_freq_dict(word_list):\n",
        "  wordfreq = [word_list.count(p) for p in word_list]\n",
        "  return dict(list(zip(word_list,wordfreq)))\n",
        "\n",
        "def create_data(x,table):\n",
        "  names = [\"sarah\",\"paul\",\"mary\",\"james\",\"art\",\"tom\",\"lary\",\n",
        "           \"anna\",\"bob\",\"joe\",\"bill\",\"martin\",\"amy\",\"timmy\",\n",
        "           'pat',\"connor\",\"eric\"]\n",
        "  for i in range(len(names)):\n",
        "    for j in range(random.randint(1,x)):   \n",
        "      table.append(names[i])"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpCJPb05S30w"
      },
      "source": [
        "set 1:\n",
        "- set one is a dataset with high variablitity in the frequency of table look-ups. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSWgGoHXL545",
        "outputId": "88835c3a-7aee-4bc1-bd89-c8afa694eb86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# data set 1\n",
        "create_data(10000,table1)\n",
        "list_to_freq_dict(table1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'amy': 1010,\n",
              " 'anna': 4819,\n",
              " 'art': 5167,\n",
              " 'bill': 8370,\n",
              " 'bob': 7518,\n",
              " 'connor': 8281,\n",
              " 'eric': 3167,\n",
              " 'james': 4670,\n",
              " 'joe': 380,\n",
              " 'lary': 786,\n",
              " 'martin': 28,\n",
              " 'mary': 2013,\n",
              " 'pat': 7144,\n",
              " 'paul': 6605,\n",
              " 'sarah': 6124,\n",
              " 'timmy': 1859,\n",
              " 'tom': 4615}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK7MHm_hS5wl"
      },
      "source": [
        "set 2:\n",
        "- set two is a dataset with low variablitity in the frequency of table look-ups. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u8M38csP1BV",
        "outputId": "ba01aebd-84fa-4ef0-cd30-68bc3d223242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# dataset 2\n",
        "create_data(5,table2)\n",
        "list_to_freq_dict(table2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'amy': 4,\n",
              " 'anna': 3,\n",
              " 'art': 5,\n",
              " 'bill': 3,\n",
              " 'bob': 2,\n",
              " 'connor': 4,\n",
              " 'eric': 2,\n",
              " 'james': 4,\n",
              " 'joe': 1,\n",
              " 'lary': 4,\n",
              " 'martin': 3,\n",
              " 'mary': 2,\n",
              " 'pat': 5,\n",
              " 'paul': 2,\n",
              " 'sarah': 1,\n",
              " 'timmy': 3,\n",
              " 'tom': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b6ckzZOTNwZ"
      },
      "source": [
        "If our data looked like **set 2** (pre table-split), we would want to use **option1**. Since the variability of the frequency is low, sorting by frequency would not be very affective. It is better in this case to sort alphabetically and do a binary search. \n",
        "\n",
        "By contrast, if our data looked like **set 1** (pre table-split), we might use **option 2**. Since the variation of look-ups varies significantly, we will save a lot of time by sorting by frequency and doing sequential look-up. This way, when we search table 1 and 2, it could, in theory, take less time on average to find names. The downside of option 2 though is that despite it taking significantly less time to find the most common names, it will take significantly longer to find less common names (since we are searching sequentially).\n",
        "\n",
        "\n",
        "Option 1 is *definatley* a better option than Dr. X's original proposal, while option 2 has the *potential* to be a better option than both Dr.X's approach and option 1. The decision to whether Option 2 is viable will be heavily influenced by the variation of frequencies in the table. A full test of both options would need to be run on multiple datasets to determine which situations are best fit for which option. \n",
        "\n",
        "\n",
        "All in all, option 1 is the safer bet. If little is known about the dataset (we can't predict the general variation in frequency or it is changing often) and time to test the methods is short, option 1 should always be chosen. \n",
        "\n",
        "On the other hand -- if much is known about the dataset (we can predict a general variation in frequency) and we have ample time to test the 2 methods on many different sets, option 2 may be the better choice."
      ]
    }
  ]
}